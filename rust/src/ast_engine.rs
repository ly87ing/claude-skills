//! AST Engine - åŒéè¯­ä¹‰åˆ†æå¼•æ“
//!
//! ğŸ›°ï¸ é›·è¾¾æ‰«æï¼šæ£€æµ‹æ€§èƒ½åæ¨¡å¼
//!
//! v9.1 æ¶æ„é‡æ„:
//! - AST è§„åˆ™ä¼˜å…ˆ (tree_sitter_java.rs)
//! - **æ‰€æœ‰è§„åˆ™å·²è¿ç§»è‡³ Tree-sitter** (v9.1)
//! - ç»Ÿä¸€è§„åˆ™ IDï¼Œæ¶ˆé™¤é‡å¤æ£€æµ‹
//!
//! ä¼˜åŒ–ç‚¹ï¼š
//! 1. ä½¿ç”¨ thread_local Parser å¤ç”¨ (v9.1)
//! 2. è¿‡æ»¤æ³¨é‡Šå†…å®¹ï¼Œé¿å…è¯¯æŠ¥
//! 3. é›†æˆ Tree-sitter AST åˆ†æ (v5.0)
//! 4. å¹¶è¡Œæ–‡ä»¶æ‰«æ (rayon) (v5.1)
//! 5. Dockerfile æ‰«æ (v5.1)
//! 6. åŒéè¯­ä¹‰å¼•æ“ (v8.0)
//! 7. è§„åˆ™å»é‡ï¼Œæ¶ˆé™¤ Regex/AST å†²çª (v9.0)
//! 8. ç§»é™¤æ‰€æœ‰ Regex è§„åˆ™ï¼Œå…¨éƒ¨ä½¿ç”¨ Tree-sitter (v9.1)

use serde_json::{json, Value};
use std::path::Path;
use std::sync::Mutex;
use walkdir::WalkDir;
use rayon::prelude::*;

use crate::scanner::{CodeAnalyzer, Issue as ScannerIssue, Severity as ScannerSeverity};
use crate::scanner::tree_sitter_java::JavaTreeSitterAnalyzer;
use crate::scanner::config::LineBasedConfigAnalyzer;
use crate::scanner::dockerfile::DockerfileAnalyzer;

// ============================================================================
// è§„åˆ™å®šä¹‰
// ============================================================================

/// é—®é¢˜ä¸¥é‡çº§åˆ«
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Severity {
    P0, // ä¸¥é‡
    P1, // è­¦å‘Š
}

/// AST æ£€æµ‹é—®é¢˜
#[derive(Debug)]
pub struct AstIssue {
    pub severity: Severity,
    pub issue_type: String,
    pub file: String,
    pub line: usize,
    pub description: String,
}

// v9.1: Regex è§„åˆ™å·²å…¨éƒ¨è¿ç§»åˆ° tree_sitter_java.rs
// ç°åœ¨æ‰€æœ‰ Java è§„åˆ™éƒ½é€šè¿‡ Tree-sitter AST åˆ†æå®ç°

// Helper to convert ScannerIssue to AstIssue
fn convert_issue(issue: ScannerIssue) -> AstIssue {
    let sev = match issue.severity {
        ScannerSeverity::P0 => Severity::P0,
        ScannerSeverity::P1 => Severity::P1,
    };
    AstIssue {
        severity: sev,
        issue_type: issue.id,
        file: issue.file,
        line: issue.line,
        description: issue.description,
    }
}

// ============================================================================
// æ ¸å¿ƒæ‰«æå‡½æ•°
// ============================================================================

/// å…¨é¡¹ç›®é›·è¾¾æ‰«æ (v9.1 ä¼˜åŒ–æ¶æ„)
///
/// ## æ€§èƒ½ä¼˜åŒ– (v9.1):
/// - **thread_local Parser å¤ç”¨**: æ¯ä¸ªçº¿ç¨‹åªåˆå§‹åŒ–ä¸€æ¬¡ Parser
/// - **é¢„ç¼–è¯‘ Query**: æ‰€æœ‰ Tree-sitter æŸ¥è¯¢åœ¨å¯åŠ¨æ—¶ç¼–è¯‘ä¸€æ¬¡
///
/// ## æ¶æ„è¯´æ˜:
/// é‡‡ç”¨ä¸¤éæ‰«ææ¶æ„æ˜¯å¿…è¦çš„ï¼Œå› ä¸º Phase 2 éœ€è¦ Phase 1 æ„å»ºçš„å…¨å±€ç¬¦å·è¡¨ï¼š
/// - Phase 1: å¹¶è¡Œæ‰«ææ‰€æœ‰ Java æ–‡ä»¶ï¼Œæå–ç±»/å­—æ®µä¿¡æ¯æ„å»ºå…¨å±€ç¬¦å·è¡¨
/// - Phase 2: ä½¿ç”¨å…¨å±€ç¬¦å·è¡¨è¿›è¡Œæ·±åº¦åˆ†æï¼ˆå¦‚ N+1 æ£€æµ‹éœ€è¦çŸ¥é“å˜é‡ç±»å‹ï¼‰
///
/// è™½ç„¶æ¯ä¸ªæ–‡ä»¶è¢«è§£æä¸¤æ¬¡ï¼Œä½†é€šè¿‡ thread_local Parser å¤ç”¨ï¼Œ
/// é¿å…äº†æ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»º Parser çš„å¼€é”€ï¼ˆä¸»è¦å¼€é”€æ˜¯ native å±‚åˆå§‹åŒ–ï¼‰ã€‚
///
/// compact: true æ—¶åªè¿”å› P0ï¼Œæ¯ä¸ª issue åªæœ‰ id/file/line
/// max_p1: compact=false æ—¶æœ€å¤šè¿”å›çš„ P1 æ•°é‡
pub fn radar_scan(code_path: &str, compact: bool, max_p1: usize) -> Result<Value, Box<dyn std::error::Error>> {
    let path = Path::new(code_path);
    let is_dir = path.is_dir();
    
    // æ”¶é›†æ‰€æœ‰å¾…æ‰«ææ–‡ä»¶
    let entries: Vec<_> = WalkDir::new(path)
        .follow_links(true)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_file())
        .collect();

    let file_count = entries.len();

    // åˆå§‹åŒ–åˆ†æå™¨ (Arc å…±äº«ï¼Œåªç¼–è¯‘ä¸€æ¬¡ queries)
    let java_analyzer = std::sync::Arc::new(JavaTreeSitterAnalyzer::new()?);
    let config_analyzer = LineBasedConfigAnalyzer::new().ok();
    let docker_analyzer = DockerfileAnalyzer::new().ok();

    // === Phase 1: Indexing (æ„å»ºå…¨å±€ç¬¦å·è¡¨) ===
    let mut symbol_table = crate::symbol_table::SymbolTable::new();
    
    // åªæœ‰ç›®å½•æ‰«æä¸”åŒ…å« Java æ–‡ä»¶æ—¶æ‰è¿›è¡Œç´¢å¼•æ„å»º
    if is_dir {
        // ä½¿ç”¨å¹¶è¡Œè¿­ä»£å™¨è¿›è¡Œç´¢å¼•
        // æ³¨æ„ï¼šç”±äº SymbolTable éœ€è¦åˆå¹¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ map/reduce
        let java_files: Vec<_> = entries.iter()
            .filter(|e| e.path().extension().and_then(|e| e.to_str()) == Some("java"))
            .collect();
            
        if !java_files.is_empty() {
            // Log indexing (optional)
            // println!("Phase 1: Indexing {} Java files...", java_files.len());
            
            let tables: Vec<crate::symbol_table::SymbolTable> = java_files.par_iter().map(|entry| {
                let mut local_table = crate::symbol_table::SymbolTable::new();
                if let Ok(content) = std::fs::read_to_string(entry.path()) {
                    if let Ok((Some(type_info), bindings)) = java_analyzer.extract_symbols(&content, entry.path()) {
                        // æ³¨å†Œç±»å’Œå­—æ®µ
                        let class_name = type_info.name.clone();
                        local_table.register_class(type_info);
                        for binding in bindings {
                            local_table.register_field(&class_name, binding);
                        }
                    }
                }
                local_table
            }).collect();
            
            // Merge all tables
            for table in tables {
                for (name, info) in table.classes {
                    symbol_table.classes.insert(name, info);
                }
                for (key, binding) in table.fields {
                    symbol_table.fields.insert(key, binding);
                }
                for (key, info) in table.methods {
                    symbol_table.methods.insert(key, info);
                }
            }
        }
    }
    
    let symbol_table_ref = &symbol_table;

    // === Phase 2: Deep Analysis (æ·±åº¦æ‰«æ) ===
    // ä½¿ç”¨ Mutex ä¿æŠ¤å…±äº«çŠ¶æ€ (rayon å¹¶è¡Œå®‰å…¨)
    let issues: Mutex<Vec<AstIssue>> = Mutex::new(Vec::new());

    // å¹¶è¡Œå¤„ç†æ–‡ä»¶
    entries.par_iter().for_each(|entry| {
        let file_path = entry.path();
        let file_name_str = file_path.file_name()
            .map(|n| n.to_string_lossy().to_string())
            .unwrap_or_default();
        let ext = file_path.extension().and_then(|e| e.to_str()).unwrap_or("");

        // æœ¬çº¿ç¨‹çš„ issues
        let mut local_issues: Vec<AstIssue> = Vec::new();

        if ext == "java" {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // v9.1: æ‰€æœ‰è§„åˆ™å·²è¿ç§»åˆ° Tree-sitter AST åˆ†æ
                // AST Analysis (with Context)
                // ä¼ å…¥å…¨å±€ SymbolTable å¼•ç”¨
                let ctx = if is_dir { Some(symbol_table_ref) } else { None };

                if let Ok(ast_results) = java_analyzer.analyze_with_context(&content, file_path, ctx) {
                    local_issues.extend(ast_results.into_iter().map(convert_issue));
                }
            }
        } else if ["yml", "yaml", "properties"].contains(&ext) {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 3. Config Analysis
                if let Some(analyzer) = &config_analyzer {
                    if let Ok(config_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(config_results.into_iter().map(convert_issue));
                    }
                }
            }
        } else if file_name_str == "Dockerfile" || file_name_str.starts_with("Dockerfile.") {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 4. Dockerfile Analysis (v5.1 NEW)
                if let Some(analyzer) = &docker_analyzer {
                    if let Ok(docker_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(docker_results.into_iter().map(convert_issue));
                    }
                }
            }
        }

        // åˆå¹¶åˆ°å…¨å±€ issues
        if !local_issues.is_empty() {
            // ä½¿ç”¨ unwrap_or_else å¤„ç† poisoned mutexï¼ˆå¦‚æœæŒé”çº¿ç¨‹ panicï¼‰
            let mut global = issues.lock().unwrap_or_else(|e| e.into_inner());
            global.extend(local_issues);
        }
    });

    // å®‰å…¨åœ°è§£åŒ…ï¼šå¦‚æœ mutex è¢« poisonedï¼Œä»ç„¶è·å–å†…éƒ¨æ•°æ®
    let issues = issues.into_inner().unwrap_or_else(|e| e.into_inner());
    let p0_count = issues.iter().filter(|i| matches!(i.severity, Severity::P0)).count();
    let p1_count = issues.iter().filter(|i| matches!(i.severity, Severity::P1)).count();

    // === æ ¹æ® compact æ¨¡å¼ç”Ÿæˆä¸åŒæŠ¥å‘Š ===
    if compact {
        // ç´§å‡‘æ¨¡å¼ï¼šåªè¿”å› P0ï¼Œç²¾ç®€æ ¼å¼
        let mut report = format!(
            "## ğŸ›°ï¸ é›·è¾¾æ‰«æ (v9.1 AST å¼•æ“)\n\n**P0**: {p0_count} | **P1**: {p1_count} | **æ–‡ä»¶**: {file_count}\n\n"
        );

        if p0_count > 0 {
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P0)) {
                report.push_str(&format!(
                    "- `{}` {}:{}\n",
                    issue.issue_type, issue.file, issue.line
                ));
            }
        } else {
            report.push_str("âœ… æ—  P0 é—®é¢˜\n");
        }

        if p1_count > 0 {
            report.push_str(&format!("\n*ï¼ˆ{p1_count} ä¸ª P1 è­¦å‘Šå·²çœç•¥ï¼Œä½¿ç”¨ compact=false æŸ¥çœ‹ï¼‰*\n"));
        }

        Ok(json!(report))
    } else {
        // å®Œæ•´æ¨¡å¼
        let mut report = format!(
            "## ğŸ›°ï¸ é›·è¾¾æ‰«æç»“æœ (v9.1 AST å¼•æ“)\n\n\
            **æ‰«æ**: {} ä¸ªæ–‡ä»¶\n\
            **å‘ç°**: {} ä¸ªå«Œç–‘ç‚¹ (P0: {}, P1: {})\n\n",
            file_count, issues.len(), p0_count, p1_count
        );

        if p0_count > 0 {
            report.push_str("### ğŸ”´ P0 ä¸¥é‡å«Œç–‘\n\n");
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P0)) {
                report.push_str(&format!(
                    "- **{}** - `{}:{}` - {}\n",
                    issue.issue_type, issue.file, issue.line, issue.description
                ));
            }
            report.push('\n');
        }

        if p1_count > 0 {
            report.push_str(&format!("### ğŸŸ¡ P1 è­¦å‘Š (æ˜¾ç¤ºå‰ {max_p1})\n\n"));
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P1)).take(max_p1) {
                report.push_str(&format!(
                    "- **{}** - `{}:{}` - {}\n",
                    issue.issue_type, issue.file, issue.line, issue.description
                ));
            }
        }

        Ok(json!(report))
    }
}

/// å•æ–‡ä»¶æ‰«æ (v9.1: ä»…ä½¿ç”¨ Tree-sitter AST åˆ†æ)
pub fn scan_source_code(code: &str, file_path: &str) -> Result<Value, Box<dyn std::error::Error>> {
    let mut issues = Vec::new();
    let path = Path::new(file_path);
    let ext = path.extension().and_then(|e| e.to_str()).unwrap_or("");

    if ext == "java" {
        // v9.1: ä»…ä½¿ç”¨ AST åˆ†æï¼ˆæ‰€æœ‰ Regex è§„åˆ™å·²è¿ç§»ï¼‰
        if let Ok(analyzer) = JavaTreeSitterAnalyzer::new() {
             if let Ok(res) = analyzer.analyze(code, path) {
                 issues.extend(res.into_iter().map(convert_issue));
             }
        }
    } else if ["yml", "yaml", "properties"].contains(&ext) {
        // Config
        if let Ok(analyzer) = LineBasedConfigAnalyzer::new() {
             if let Ok(res) = analyzer.analyze(code, path) {
                 issues.extend(res.into_iter().map(convert_issue));
             }
        }
    }

    let mut report = format!("## ğŸ›°ï¸ æ‰«æ: {file_path}\n\n");

    if issues.is_empty() {
        report.push_str("âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½é—®é¢˜\n");
    } else {
        for issue in &issues {
            let emoji = match issue.severity {
                Severity::P0 => "ğŸ”´",
                Severity::P1 => "ğŸŸ¡",
            };
            report.push_str(&format!(
                "{} **{}** (è¡Œ {}) - {}\n",
                emoji, issue.issue_type, issue.line, issue.description
            ));
        }
    }

    Ok(json!(report))
}
