//! AST Engine - åŒéè¯­ä¹‰åˆ†æå¼•æ“
//!
//! ğŸ›°ï¸ é›·è¾¾æ‰«æï¼šæ£€æµ‹æ€§èƒ½åæ¨¡å¼
//!
//! v9.0 æ¶æ„é‡æ„:
//! - AST è§„åˆ™ä¼˜å…ˆ (tree_sitter_java.rs)
//! - Regex ä»…ç”¨äºæ— æ³•ç”¨ AST è¡¨è¾¾çš„è§„åˆ™ (SQL æ£€æµ‹ã€HTTP å®¢æˆ·ç«¯æç¤º)
//! - ç»Ÿä¸€è§„åˆ™ IDï¼Œæ¶ˆé™¤é‡å¤æ£€æµ‹
//!
//! ä¼˜åŒ–ç‚¹ï¼š
//! 1. ä½¿ç”¨ once_cell é™æ€ç¼–è¯‘æ­£åˆ™ï¼Œé¿å…é‡å¤åˆ›å»º
//! 2. è¿‡æ»¤æ³¨é‡Šå†…å®¹ï¼Œé¿å…è¯¯æŠ¥
//! 3. é›†æˆ Tree-sitter AST åˆ†æ (v5.0)
//! 4. å¹¶è¡Œæ–‡ä»¶æ‰«æ (rayon) (v5.1)
//! 5. Dockerfile æ‰«æ (v5.1)
//! 6. åŒéè¯­ä¹‰å¼•æ“ (v8.0)
//! 7. è§„åˆ™å»é‡ï¼Œæ¶ˆé™¤ Regex/AST å†²çª (v9.0)

use once_cell::sync::Lazy;
use regex::Regex;
use serde_json::{json, Value};
use std::path::Path;
use std::sync::Mutex;
use walkdir::WalkDir;
use rayon::prelude::*;

use crate::scanner::{CodeAnalyzer, Issue as ScannerIssue, Severity as ScannerSeverity};
use crate::scanner::tree_sitter_java::JavaTreeSitterAnalyzer;
use crate::scanner::config::LineBasedConfigAnalyzer;
use crate::scanner::dockerfile::DockerfileAnalyzer;

// ============================================================================
// é™æ€ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåªç¼–è¯‘ä¸€æ¬¡ï¼Œå…¨å±€å¤ç”¨ï¼‰
// ============================================================================
//
// v9.0 è¯´æ˜ï¼šå¤§éƒ¨åˆ†è§„åˆ™å·²è¿ç§»è‡³ tree_sitter_java.rs ä½¿ç”¨ AST åˆ†æ
// ä»¥ä¸‹åªä¿ç•™ã€Œæ— æ³•ç”¨ AST è¡¨è¾¾ã€æˆ–ã€ŒRegex æ›´é«˜æ•ˆã€çš„è§„åˆ™ï¼š
// 1. SQL å­—ç¬¦ä¸²æ£€æµ‹ (éœ€è¦åŒ¹é…å­—ç¬¦ä¸²å­—é¢é‡å†…å®¹)
// 2. HTTP å®¢æˆ·ç«¯ä½¿ç”¨æç¤º (ä»…ä½œä¸ºçº¿ç´¢ï¼Œéç²¾ç¡®æ£€æµ‹)
// 3. æ— ç•Œç¼“å­˜ Map/List (static å­—æ®µçš„æ³›å‹ç±»å‹åŒ¹é…)
// 4. å¼‚å¸¸å¤„ç† (ä»…æ‰“å°/åæ²¡ï¼Œä½œä¸º AST è§„åˆ™çš„è¡¥å……)
// ============================================================================

/// æ³¨é‡ŠåŒ¹é…æ­£åˆ™ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
static COMMENT_REGEX: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"//.*$|/\*[\s\S]*?\*/").unwrap()
});

// === æ•°æ®åº“ SQL æ£€æµ‹ (æ— æ³•ç”¨ AST ç²¾ç¡®åŒ¹é…å­—ç¬¦ä¸²å†…å®¹) ===
static RE_SELECT_STAR: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r#"["']SELECT\s+\*\s+FROM"#).unwrap()
});
static RE_LIKE_LEADING_WILDCARD: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r#"LIKE\s+['"]%"#).unwrap()
});

// === HTTP å®¢æˆ·ç«¯æç¤º (ä»…ä½œä¸ºçº¿ç´¢æç¤ºæ£€æŸ¥è¶…æ—¶é…ç½®) ===
static RE_HTTP_CLIENT_USAGE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(HttpClient|RestTemplate|OkHttp|WebClient)\s*\.").unwrap()
});

// === æ— ç•Œç¼“å­˜æ£€æµ‹ (static æ³›å‹å­—æ®µï¼ŒAST è§„åˆ™ä½œä¸ºä¸»è¦æ£€æµ‹) ===
// æ³¨æ„: STATIC_COLLECTION_AST å·²åœ¨ tree_sitter_java.rs ä¸­å®ç°
// è¿™é‡Œä¿ç•™ä½œä¸ºè¡¥å……ï¼Œç”¨äºæ£€æµ‹æ›´å¤æ‚çš„æ³›å‹å£°æ˜æ¨¡å¼
static RE_UNBOUNDED_CACHE_MAP: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"static\s+.*Map\s*<[^>]+>\s*\w+\s*=\s*new").unwrap()
});
static RE_UNBOUNDED_CACHE_LIST: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"static\s+.*(List|Set)\s*<[^>]+>\s*\w+\s*=\s*new").unwrap()
});

// === å¼‚å¸¸å¤„ç†è¡¥å……æ£€æµ‹ (AST ä¸»æ£€æµ‹ï¼Œè¿™é‡Œä½œä¸ºè¡¥å……) ===
static RE_EXCEPTION_SWALLOW: Lazy<Regex> = Lazy::new(|| {
    // catch åä»…æ‰“å° (e.printStackTrace ç­‰)
    Regex::new(r"catch\s*\([^)]+\)\s*\{[^}]*\.print").unwrap()
});

// === ç¼“å­˜é…ç½®æ£€æµ‹ (éœ€è¦é¢å¤–ä¸Šä¸‹æ–‡éªŒè¯) ===
static RE_CACHE_NO_EXPIRE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(Caffeine|CacheBuilder)\s*\.\s*newBuilder").unwrap()
});

// ============================================================================
// è§„åˆ™å®šä¹‰
// ============================================================================

/// é—®é¢˜ä¸¥é‡çº§åˆ«
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Severity {
    P0, // ä¸¥é‡
    P1, // è­¦å‘Š
}

/// AST æ£€æµ‹é—®é¢˜
#[derive(Debug)]
pub struct AstIssue {
    pub severity: Severity,
    pub issue_type: String,
    pub file: String,
    pub line: usize,
    pub description: String,
}

/// è§„åˆ™é…ç½®
struct Rule {
    id: &'static str,
    description: &'static str,
    severity: Severity,
    regex: &'static Lazy<Regex>,
}

/// ç²¾ç®€è§„åˆ™é›† (v9.0)
///
/// åªä¿ç•™ã€Œæ— æ³•ç”¨ AST è¡¨è¾¾ã€æˆ–ã€Œä½œä¸º AST è§„åˆ™è¡¥å……ã€çš„ Regex è§„åˆ™ï¼š
/// - SQL æ£€æµ‹ï¼šéœ€è¦åŒ¹é…å­—ç¬¦ä¸²å­—é¢é‡å†…å®¹
/// - HTTP å®¢æˆ·ç«¯æç¤ºï¼šä»…ä½œä¸ºçº¿ç´¢
/// - æ— ç•Œç¼“å­˜ï¼šè¡¥å…… AST çš„æ³›å‹æ£€æµ‹
/// - å¼‚å¸¸å¤„ç†ï¼šè¡¥å…… AST çš„ç©º catch æ£€æµ‹
fn get_rules() -> Vec<Rule> {
    vec![
        // === SQL æ£€æµ‹ (æ— æ³•ç”¨ AST ç²¾ç¡®åŒ¹é…å­—ç¬¦ä¸²å†…å®¹) ===
        Rule { id: "SELECT_STAR", description: "SELECT * æŸ¥è¯¢ï¼Œå»ºè®®æ˜ç¡®æŒ‡å®šå­—æ®µ", severity: Severity::P1, regex: &RE_SELECT_STAR },
        Rule { id: "LIKE_LEADING_WILDCARD", description: "LIKE '%xxx' å‰å¯¼é€šé…ç¬¦å¯¼è‡´å…¨è¡¨æ‰«æ", severity: Severity::P0, regex: &RE_LIKE_LEADING_WILDCARD },

        // === HTTP å®¢æˆ·ç«¯æç¤º (ä»…ä½œä¸ºçº¿ç´¢) ===
        Rule { id: "HTTP_CLIENT_CHECK_TIMEOUT", description: "HTTP å®¢æˆ·ç«¯ä½¿ç”¨ï¼Œè¯·ç¡®è®¤å·²é…ç½®è¶…æ—¶", severity: Severity::P1, regex: &RE_HTTP_CLIENT_USAGE },

        // === æ— ç•Œç¼“å­˜è¡¥å……æ£€æµ‹ ===
        // ä¸»æ£€æµ‹ç”± STATIC_COLLECTION_AST å®Œæˆï¼Œè¿™é‡Œæ£€æµ‹æ›´å¤æ‚çš„æ³›å‹æ¨¡å¼
        Rule { id: "UNBOUNDED_CACHE_MAP", description: "æ— ç•Œç¼“å­˜ static Map (è¯·é…ç½®å¤§å°é™åˆ¶)", severity: Severity::P0, regex: &RE_UNBOUNDED_CACHE_MAP },
        Rule { id: "UNBOUNDED_CACHE_LIST", description: "æ— ç•Œç¼“å­˜ static List/Set (è¯·é…ç½®å¤§å°é™åˆ¶)", severity: Severity::P0, regex: &RE_UNBOUNDED_CACHE_LIST },

        // === å¼‚å¸¸å¤„ç†è¡¥å……æ£€æµ‹ ===
        // ä¸»æ£€æµ‹ç”± EMPTY_CATCH_AST å®Œæˆï¼Œè¿™é‡Œæ£€æµ‹ä»…æ‰“å°çš„æƒ…å†µ
        Rule { id: "EXCEPTION_SWALLOW", description: "å¼‚å¸¸è¢«åæ²¡ (ä»…æ‰“å°)ï¼Œå»ºè®®æ­£ç¡®å¤„ç†æˆ–é‡æŠ›", severity: Severity::P1, regex: &RE_EXCEPTION_SWALLOW },

        // === ç¼“å­˜é…ç½®æ£€æµ‹ (éœ€è¦é¢å¤–ä¸Šä¸‹æ–‡éªŒè¯) ===
        // æ³¨æ„ï¼šè¿™åªæ˜¯æç¤ºï¼Œå®é™…éœ€è¦æ£€æŸ¥æ˜¯å¦é…ç½®äº† expire/maximumSize
        // Rule { id: "CACHE_NO_EXPIRE", ... } -- ç§»åŠ¨åˆ° analyze_java_code ä¸­åšç‰¹æ®Šå¤„ç†
    ]
}

// Helper to convert ScannerIssue to AstIssue
fn convert_issue(issue: ScannerIssue) -> AstIssue {
    let sev = match issue.severity {
        ScannerSeverity::P0 => Severity::P0,
        ScannerSeverity::P1 => Severity::P1,
    };
    AstIssue {
        severity: sev,
        issue_type: issue.id,
        file: issue.file,
        line: issue.line,
        description: issue.description,
    }
}

// ============================================================================
// æ ¸å¿ƒæ‰«æå‡½æ•°
// ============================================================================

/// å…¨é¡¹ç›®é›·è¾¾æ‰«æ (v8.0 åŒéæ¶æ„)
/// 
/// compact: true æ—¶åªè¿”å› P0ï¼Œæ¯ä¸ª issue åªæœ‰ id/file/line
/// max_p1: compact=false æ—¶æœ€å¤šè¿”å›çš„ P1 æ•°é‡
pub fn radar_scan(code_path: &str, compact: bool, max_p1: usize) -> Result<Value, Box<dyn std::error::Error>> {
    let path = Path::new(code_path);
    let is_dir = path.is_dir();
    
    // æ”¶é›†æ‰€æœ‰å¾…æ‰«ææ–‡ä»¶
    let entries: Vec<_> = WalkDir::new(path)
        .follow_links(true)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_file())
        .collect();

    let file_count = entries.len();

    // åˆå§‹åŒ–åˆ†æå™¨ (Arc å…±äº«ï¼Œåªç¼–è¯‘ä¸€æ¬¡ queries)
    let java_analyzer = std::sync::Arc::new(JavaTreeSitterAnalyzer::new()?);
    let config_analyzer = LineBasedConfigAnalyzer::new().ok();
    let docker_analyzer = DockerfileAnalyzer::new().ok();

    // === Phase 1: Indexing (æ„å»ºå…¨å±€ç¬¦å·è¡¨) ===
    let mut symbol_table = crate::symbol_table::SymbolTable::new();
    
    // åªæœ‰ç›®å½•æ‰«æä¸”åŒ…å« Java æ–‡ä»¶æ—¶æ‰è¿›è¡Œç´¢å¼•æ„å»º
    if is_dir {
        // ä½¿ç”¨å¹¶è¡Œè¿­ä»£å™¨è¿›è¡Œç´¢å¼•
        // æ³¨æ„ï¼šç”±äº SymbolTable éœ€è¦åˆå¹¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ map/reduce
        let java_files: Vec<_> = entries.iter()
            .filter(|e| e.path().extension().and_then(|e| e.to_str()) == Some("java"))
            .collect();
            
        if !java_files.is_empty() {
            // Log indexing (optional)
            // println!("Phase 1: Indexing {} Java files...", java_files.len());
            
            let tables: Vec<crate::symbol_table::SymbolTable> = java_files.par_iter().map(|entry| {
                let mut local_table = crate::symbol_table::SymbolTable::new();
                if let Ok(content) = std::fs::read_to_string(entry.path()) {
                    if let Ok((Some(type_info), bindings)) = java_analyzer.extract_symbols(&content, entry.path()) {
                        // æ³¨å†Œç±»å’Œå­—æ®µ
                        let class_name = type_info.name.clone();
                        local_table.register_class(type_info);
                        for binding in bindings {
                            local_table.register_field(&class_name, binding);
                        }
                    }
                }
                local_table
            }).collect();
            
            // Merge all tables
            for table in tables {
                for (name, info) in table.classes {
                    symbol_table.classes.insert(name, info);
                }
                for (key, binding) in table.fields {
                    symbol_table.fields.insert(key, binding);
                }
                for (key, info) in table.methods {
                    symbol_table.methods.insert(key, info);
                }
            }
        }
    }
    
    let symbol_table_ref = &symbol_table;

    // === Phase 2: Deep Analysis (æ·±åº¦æ‰«æ) ===
    // ä½¿ç”¨ Mutex ä¿æŠ¤å…±äº«çŠ¶æ€ (rayon å¹¶è¡Œå®‰å…¨)
    let issues: Mutex<Vec<AstIssue>> = Mutex::new(Vec::new());

    // å¹¶è¡Œå¤„ç†æ–‡ä»¶
    entries.par_iter().for_each(|entry| {
        let file_path = entry.path();
        let file_name_str = file_path.file_name()
            .map(|n| n.to_string_lossy().to_string())
            .unwrap_or_default();
        let ext = file_path.extension().and_then(|e| e.to_str()).unwrap_or("");

        // æœ¬çº¿ç¨‹çš„ issues
        let mut local_issues: Vec<AstIssue> = Vec::new();

        if ext == "java" {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 1. Regex Analysis (Legacy - still useful for some non-AST rules)
                let legacy = analyze_java_code(&content, &file_path.to_string_lossy());
                local_issues.extend(legacy);

                // 2. AST Analysis (with Context)
                // ä¼ å…¥å…¨å±€ SymbolTable å¼•ç”¨
                let ctx = if is_dir { Some(symbol_table_ref) } else { None };
                
                if let Ok(ast_results) = java_analyzer.analyze_with_context(&content, file_path, ctx) {
                    local_issues.extend(ast_results.into_iter().map(convert_issue));
                }
            }
        } else if ["yml", "yaml", "properties"].contains(&ext) {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 3. Config Analysis
                if let Some(analyzer) = &config_analyzer {
                    if let Ok(config_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(config_results.into_iter().map(convert_issue));
                    }
                }
            }
        } else if file_name_str == "Dockerfile" || file_name_str.starts_with("Dockerfile.") {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 4. Dockerfile Analysis (v5.1 NEW)
                if let Some(analyzer) = &docker_analyzer {
                    if let Ok(docker_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(docker_results.into_iter().map(convert_issue));
                    }
                }
            }
        }

        // åˆå¹¶åˆ°å…¨å±€ issues
        if !local_issues.is_empty() {
            // ä½¿ç”¨ unwrap_or_else å¤„ç† poisoned mutexï¼ˆå¦‚æœæŒé”çº¿ç¨‹ panicï¼‰
            let mut global = issues.lock().unwrap_or_else(|e| e.into_inner());
            global.extend(local_issues);
        }
    });

    // å®‰å…¨åœ°è§£åŒ…ï¼šå¦‚æœ mutex è¢« poisonedï¼Œä»ç„¶è·å–å†…éƒ¨æ•°æ®
    let issues = issues.into_inner().unwrap_or_else(|e| e.into_inner());
    let p0_count = issues.iter().filter(|i| matches!(i.severity, Severity::P0)).count();
    let p1_count = issues.iter().filter(|i| matches!(i.severity, Severity::P1)).count();

    // === æ ¹æ® compact æ¨¡å¼ç”Ÿæˆä¸åŒæŠ¥å‘Š ===
    if compact {
        // ç´§å‡‘æ¨¡å¼ï¼šåªè¿”å› P0ï¼Œç²¾ç®€æ ¼å¼
        let mut report = format!(
            "## ğŸ›°ï¸ é›·è¾¾æ‰«æ (v8.0 åŒéå¼•æ“)\n\n**P0**: {p0_count} | **P1**: {p1_count} | **æ–‡ä»¶**: {file_count}\n\n"
        );

        if p0_count > 0 {
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P0)) {
                report.push_str(&format!(
                    "- `{}` {}:{}\n",
                    issue.issue_type, issue.file, issue.line
                ));
            }
        } else {
            report.push_str("âœ… æ—  P0 é—®é¢˜\n");
        }

        if p1_count > 0 {
            report.push_str(&format!("\n*ï¼ˆ{p1_count} ä¸ª P1 è­¦å‘Šå·²çœç•¥ï¼Œä½¿ç”¨ compact=false æŸ¥çœ‹ï¼‰*\n"));
        }

        Ok(json!(report))
    } else {
        // å®Œæ•´æ¨¡å¼
        let mut report = format!(
            "## ğŸ›°ï¸ é›·è¾¾æ‰«æç»“æœ (v8.0 åŒéå¼•æ“)\n\n\
            **æ‰«æ**: {} ä¸ªæ–‡ä»¶\n\
            **å‘ç°**: {} ä¸ªå«Œç–‘ç‚¹ (P0: {}, P1: {})\n\n",
            file_count, issues.len(), p0_count, p1_count
        );

        if p0_count > 0 {
            report.push_str("### ğŸ”´ P0 ä¸¥é‡å«Œç–‘\n\n");
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P0)) {
                report.push_str(&format!(
                    "- **{}** - `{}:{}` - {}\n",
                    issue.issue_type, issue.file, issue.line, issue.description
                ));
            }
            report.push('\n');
        }

        if p1_count > 0 {
            report.push_str(&format!("### ğŸŸ¡ P1 è­¦å‘Š (æ˜¾ç¤ºå‰ {max_p1})\n\n"));
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P1)).take(max_p1) {
                report.push_str(&format!(
                    "- **{}** - `{}:{}` - {}\n",
                    issue.issue_type, issue.file, issue.line, issue.description
                ));
            }
        }

        Ok(json!(report))
    }
}

/// å•æ–‡ä»¶æ‰«æ
pub fn scan_source_code(code: &str, file_path: &str) -> Result<Value, Box<dyn std::error::Error>> {
    let mut issues = Vec::new();
    let path = Path::new(file_path);
    let ext = path.extension().and_then(|e| e.to_str()).unwrap_or("");

    if ext == "java" {
        // Regex
        issues.extend(analyze_java_code(code, file_path));
        // AST
        if let Ok(analyzer) = JavaTreeSitterAnalyzer::new() {
             if let Ok(res) = analyzer.analyze(code, path) {
                 issues.extend(res.into_iter().map(convert_issue));
             }
        }
    } else if ["yml", "yaml", "properties"].contains(&ext) {
        // Config
        if let Ok(analyzer) = LineBasedConfigAnalyzer::new() {
             if let Ok(res) = analyzer.analyze(code, path) {
                 issues.extend(res.into_iter().map(convert_issue));
             }
        }
    }

    let mut report = format!("## ğŸ›°ï¸ æ‰«æ: {file_path}\n\n");

    if issues.is_empty() {
        report.push_str("âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½é—®é¢˜\n");
    } else {
        for issue in &issues {
            let emoji = match issue.severity {
                Severity::P0 => "ğŸ”´",
                Severity::P1 => "ğŸŸ¡",
            };
            report.push_str(&format!(
                "{} **{}** (è¡Œ {}) - {}\n",
                emoji, issue.issue_type, issue.line, issue.description
            ));
        }
    }

    Ok(json!(report))
}

/// åˆ†æ Java ä»£ç ï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ - Legacy Regexï¼‰
fn analyze_java_code(code: &str, file_path: &str) -> Vec<AstIssue> {
    let mut issues = Vec::new();
    let file_name = Path::new(file_path)
        .file_name()
        .map(|n| n.to_string_lossy().to_string())
        .unwrap_or_else(|| file_path.to_string());

    // 1. ç§»é™¤æ³¨é‡Šï¼Œé¿å…è¯¯æŠ¥
    let code_without_comments = COMMENT_REGEX.replace_all(code, "");

    // 2. ç‰¹æ®Šæ£€æµ‹ï¼šThreadLocal (MIGRATED TO AST -> DISABLED HERE)
    /*
    if RE_THREADLOCAL.is_match(&code_without_comments) {
        if !code_without_comments.contains(".remove()") {
            if let Some(mat) = RE_THREADLOCAL.find(&code_without_comments) {
                let line_num = code_without_comments[..mat.start()].matches('\n').count() + 1;
                issues.push(AstIssue {
                    severity: Severity::P0,
                    issue_type: "THREADLOCAL_LEAK".to_string(),
                    file: file_name.clone(),
                    line: line_num,
                    description: "ThreadLocal æœªè°ƒç”¨ remove()ï¼Œçº¿ç¨‹æ± å¤ç”¨ä¼šå¯¼è‡´å†…å­˜æ³„éœ²".to_string(),
                });
            }
        }
    }
    */

    // 3. ç‰¹æ®Šæ£€æµ‹ï¼šCache éœ€è¦ expire é…ç½®
    if RE_CACHE_NO_EXPIRE.is_match(&code_without_comments)
        && !code_without_comments.contains("expire") && !code_without_comments.contains("maximumSize") {
            if let Some(mat) = RE_CACHE_NO_EXPIRE.find(&code_without_comments) {
                let line_num = code_without_comments[..mat.start()].matches('\n').count() + 1;
                issues.push(AstIssue {
                    severity: Severity::P1,
                    issue_type: "CACHE_NO_EXPIRE".to_string(),
                    file: file_name.clone(),
                    line: line_num,
                    description: "Caffeine/Guava Cache æœªè®¾ç½® expire æˆ– maximumSize".to_string(),
                });
            }
        }

    // 4. ä½¿ç”¨é™æ€ç¼–è¯‘çš„æ­£åˆ™è¿›è¡ŒåŒ¹é…
    let rules = get_rules();
    for rule in &rules {
        // è·³è¿‡å·²ç‰¹æ®Šå¤„ç†çš„è§„åˆ™
        if rule.id == "CACHE_NO_EXPIRE" {
            continue;
        }

        if rule.regex.is_match(&code_without_comments) {
            if let Some(mat) = rule.regex.find(&code_without_comments) {
                let line_num = code_without_comments[..mat.start()].matches('\n').count() + 1;

                // å»é‡
                let exists = issues.iter().any(|i| i.issue_type == rule.id && i.line == line_num);

                if !exists {
                    issues.push(AstIssue {
                        severity: rule.severity,
                        issue_type: rule.id.to_string(),
                        file: file_name.clone(),
                        line: line_num,
                        description: rule.description.to_string(),
                    });
                }
            }
        }
    }

    issues
}
